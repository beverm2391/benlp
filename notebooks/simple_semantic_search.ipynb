{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import openai\n",
    "from typing import List, Union, Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOC PREPROCESSING\n",
    "# Step 1: Parse the data (ur/pdf/pptx) and extract the text\n",
    "#  - make sure to preserve latex and images from the pdfs\n",
    "#  - make sure the text chunks are large enough to be meaningfu\n",
    "# Step 2: Embed the text\n",
    "# Step 3: Save in a dataframe with (doc_id, doc_title, doc_category, doc_text, doc_embedding)\n",
    "# Step 4: Save metadata (actual doc file, images, citation, etc.)\n",
    "\n",
    "# DOC SEARCH\n",
    "# Step 1: Embed the query\n",
    "# Step 2: Find the closest embedding\n",
    "# Step 3: Return the top_k results with some range (e.g. previous 1, next 1)\n",
    "# Step 4: Create a prompt with the query and the context\n",
    "# Step 5: Return the prompt stream to the user\n",
    "#  - I also want to return the metadata for the doc (e.g. doc_id, file, citation, images, category, etc.)\n",
    "#  - GET THE REGULAR EMBEDDED SEARCH WORKING FIRST\n",
    "#  - then figure out a way to return the metadata and visualizations like pdf file, images, diagrams, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Parse the data (ur/pdf/pptx) and extract the text\n",
    "#  - make sure to preserve latex and images from the pdfs\n",
    "#  - make sure the text chunks are large enough to be meaningfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf():\n",
    "    pass\n",
    "\n",
    "def parse_pptx():\n",
    "    pass\n",
    "\n",
    "def parse_url():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text):\n",
    "    \"\"\"\n",
    "    Sanitize the input text by removing unsupported characters, trimming whitespace, and checking for empty strings.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be sanitized.\n",
    "\n",
    "    Returns:\n",
    "        str: The sanitized text, or None if the text is empty after sanitization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove any characters that are not supported by the tokenizer\n",
    "    # This example assumes the tokenizer supports ASCII characters, digits, and common punctuation\n",
    "    # You can modify the regular expression to match the specific tokenizer requirements\n",
    "    sanitized_text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
    "\n",
    "    # Trim leading and trailing whitespace\n",
    "    sanitized_text = sanitized_text.strip()\n",
    "\n",
    "    # Check for empty strings\n",
    "    if not sanitized_text:\n",
    "        return None\n",
    "\n",
    "    return sanitized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_ada(text: str):\n",
    "    \"\"\"\n",
    "    Embed a text string using the ADA model.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        raise TypeError(\n",
    "            \"Text must be a string. Use embed_ada_list() to embed a list of strings.\")\n",
    "\n",
    "    sanitized_text = sanitize_text(text).replace(\"\\n\", \" \").strip()\n",
    "    if sanitized_text == \"\":\n",
    "        raise ValueError(\"Empty text passed to embed_text()\")\n",
    "\n",
    "    # Embed the text\n",
    "    response = openai.Embedding.create(\n",
    "        input=sanitized_text,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "    )\n",
    "    embedding = response[\"data\"][0][\"embedding\"]\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def embed_ada_list(text_list: List):\n",
    "    if not isinstance(text_list, list):\n",
    "        raise TypeError(\n",
    "            \"Text must be a list. Use embed_ada() to embed a single string.\")\n",
    "    sanitized_list = [sanitize_text(t).replace(\n",
    "        \"\\n\", \" \").strip() for t in text_list if t != \"\"]\n",
    "    if len(sanitized_list) == 0:\n",
    "        raise ValueError(\"Empty list passed to embed_text()\")\n",
    "    # Embed the text\n",
    "    response = openai.Embedding.create(\n",
    "        input=sanitized_list,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "    )\n",
    "    embeddings = [item[\"embedding\"] for item in response[\"data\"]]\n",
    "    return embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
